# Pain Radar: –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ

## –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: 2026-01-21

---

## üìä –°–≤–æ–¥–∫–∞ –ø–æ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –¥–∞–Ω–Ω—ã—Ö

### ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (100% –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ)

| –ò—Å—Ç–æ—á–Ω–∏–∫ | API | –î–æ—Å—Ç—É–ø | Rate Limits | –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö |
|----------|-----|--------|-------------|-----------------|
| **Reddit** | PRAW (Python), snoowrap (Node) | ‚úÖ –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π | 60 req/min | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê –û—Ç–ª–∏—á–Ω–æ–µ |
| **Hacker News** | Algolia HN API | ‚úÖ –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π | –ù–µ—Ç (–ø–∞–≥–∏–Ω–∞—Ü–∏—è –¥–æ 1000) | ‚≠ê‚≠ê‚≠ê‚≠ê –í—ã—Å–æ–∫–æ–µ |
| **IndieHackers** | Web scraping | ‚úÖ –ü—É–±–ª–∏—á–Ω—ã–π | N/A | ‚≠ê‚≠ê‚≠ê‚≠ê –í—ã—Å–æ–∫–æ–µ |
| **ProductHunt** | GraphQL API | ‚úÖ –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π (—Å –∫–ª—é—á–æ–º) | 100 req/hour | ‚≠ê‚≠ê‚≠ê‚≠ê –í—ã—Å–æ–∫–æ–µ |

### ‚ö†Ô∏è –ü–ª–∞—Ç–Ω—ã–µ/–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏

| –ò—Å—Ç–æ—á–Ω–∏–∫ | –°—Ç–æ–∏–º–æ—Å—Ç—å | –ü—Ä–æ–±–ª–µ–º–∞ |
|----------|-----------|----------|
| **Twitter/X API** | $42,000/–º–µ—Å Enterprise | ‚ùå 1 req/15 min –Ω–∞ free tier |
| **Threads** | –¢—Ä–µ–±—É–µ—Ç Business –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é | ‚ö†Ô∏è –î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ |
| **Instagram** | –ó–∞–∫—Ä—ã—Ç—ã–π API | ‚ùå –ù–µ—Ç –ø—É–±–ª–∏—á–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ |

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è PASEKA IT CRM

### –§–∞–∑–∞ 1: MVP (2-3 –Ω–µ–¥–µ–ª–∏)

**–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö:**
1. ‚úÖ **Reddit** - –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫ (—É–∂–µ –≤ –ø–ª–∞–Ω–µ)
2. ‚úÖ **Hacker News** - –¥–æ–±–∞–≤–∏—Ç—å —á–µ—Ä–µ–∑ Algolia API
3. ‚úÖ **IndieHackers** - —Ä—É—á–Ω–æ–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–ª–∏ scraping

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫:**
```
Reddit:     snoowrap (—É–∂–µ –≤—ã–±—Ä–∞–Ω) ‚úì
HN:         Algolia HN REST API (–Ω–æ–≤–æ–µ)
AI:         Claude Opus 4.5 —á–µ—Ä–µ–∑ OpenRouter (—É–∂–µ –≤—ã–±—Ä–∞–Ω) ‚úì
Database:   PostgreSQL + Prisma (—É–∂–µ –µ—Å—Ç—å) ‚úì
```

---

## üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è

### 1. Reddit Integration (‚úÖ –£–∂–µ –≤ –ø–ª–∞–Ω–µ)

**–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞:** `snoowrap`
```javascript
import Snoowrap from 'snoowrap'

const reddit = new Snoowrap({
  userAgent: 'PASEKA_CRM_PainRadar/1.0',
  clientId: process.env.REDDIT_CLIENT_ID,
  clientSecret: process.env.REDDIT_CLIENT_SECRET,
  refreshToken: process.env.REDDIT_REFRESH_TOKEN,
})
```

**Best Practices –∏–∑ —É—Å–ø–µ—à–Ω—ã—Ö –∫–µ–π—Å–æ–≤:**
- ‚úÖ Age filtering: 5-90 –¥–Ω–µ–π (—Å–≤–µ–∂–∏–µ, –Ω–æ –Ω–µ —à—É–º)
- ‚úÖ Deduplication —á–µ—Ä–µ–∑ platformId
- ‚úÖ Score threshold: –º–∏–Ω–∏–º—É–º 5-10 upvotes
- ‚úÖ Comment count filter: –º–∏–Ω–∏–º—É–º 3-5 –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤

**Subreddits –¥–ª—è B2B/IT –±–æ–ª–µ–π:**
```javascript
const targetSubreddits = [
  'startups',
  'entrepreneur',
  'smallbusiness',
  'SaaS',
  'ProductManagement',
  'webdev',
  'programming',
  'freelance',
  'digitalnomad',
  'productivity',
  'RemoteWork'
]
```

---

### 2. Hacker News Integration (üÜï –ù–æ–≤–æ–µ)

**API:** Algolia HN Search API (100% –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π)

**Endpoints:**
```
Search by relevance: GET https://hn.algolia.com/api/v1/search?query=...
Search by date:      GET https://hn.algolia.com/api/v1/search_by_date?query=...
Get item details:    GET https://hn.algolia.com/api/v1/items/:id
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
```typescript
interface HNSearchParams {
  query: string              // –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
  tags: string               // –§–∏–ª—å—Ç—Ä: 'story', 'ask_hn', 'show_hn', 'job'
  numericFilters?: string    // –ù–∞–ø—Ä–∏–º–µ—Ä: 'points>50,num_comments>5'
  hitsPerPage: number        // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 20, –º–∞–∫—Å 1000
  page: number               // –°—Ç—Ä–∞–Ω–∏—Ü–∞ (0-based)
}
```

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
```typescript
// lib/social/hackernews.ts
export async function searchHackerNews(keyword: string, limit: number = 50) {
  const params = new URLSearchParams({
    query: keyword,
    tags: 'ask_hn,show_hn',  // –¢–æ–ª—å–∫–æ Ask HN –∏ Show HN
    numericFilters: 'points>20,num_comments>3',
    hitsPerPage: limit.toString(),
  })

  const response = await fetch(
    `https://hn.algolia.com/api/v1/search_by_date?${params}`
  )
  const data = await response.json()

  return data.hits.map(hit => ({
    id: hit.objectID,
    author: hit.author,
    title: hit.title,
    content: hit.story_text || hit.title,
    url: `https://news.ycombinator.com/item?id=${hit.objectID}`,
    score: hit.points,
    comments: hit.num_comments,
    createdAt: new Date(hit.created_at),
  }))
}
```

**–õ—É—á—à–∏–µ tags –¥–ª—è –±–æ–ª–µ–π:**
- `ask_hn` - –≤–æ–ø—Ä–æ—Å—ã –æ—Ç –∫–æ–º—å—é–Ω–∏—Ç–∏ (–ø—Ä–æ–±–ª–µ–º—ã)
- `show_hn` - –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–µ—à–µ–Ω–∏–π
- –§–∏–ª—å—Ç—Ä –ø–æ points > 20 –∏ comments > 5

---

### 3. AI Analysis Architecture (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)

**–î–≤—É—Ö—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–π –ø–æ–¥—Ö–æ–¥** (–∏–∑ —É—Å–ø–µ—à–Ω—ã—Ö –∫–µ–π—Å–æ–≤):

#### Stage 1: Filtering (–±—ã—Å—Ç—Ä–æ –∏ –¥–µ—à–µ–≤–æ)
```typescript
// –ò—Å–ø–æ–ª—å–∑—É–µ–º Claude Haiku –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
const MODEL_FILTER = 'anthropic/claude-3-haiku'

async function filterRelevantPosts(posts: SocialPost[]) {
  const prompt = `
–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –±–∏–∑–Ω–µ—Å-–ø—Ä–æ–±–ª–µ–º –≤ IT.

–û—Ü–µ–Ω–∏ –∫–∞–∂–¥—ã–π –ø–æ—Å—Ç –ø–æ —à–∫–∞–ª–µ 0-100 –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –†–ï–ê–õ–¨–ù–û–ô –±–∏–∑–Ω–µ—Å-–±–æ–ª–∏:
- 80-100: –°–µ—Ä—å–µ–∑–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞, —Ç—Ä–µ–±—É—é—â–∞—è —Ä–µ—à–µ–Ω–∏—è
- 50-79: –£–º–µ—Ä–µ–Ω–Ω–∞—è –±–æ–ª—å, –µ—Å—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª
- 0-49: –ù–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ

–ü–æ—Å—Ç—ã:
${posts.map((p, i) => `${i + 1}. ${p.title}\n${p.content.substring(0, 200)}`).join('\n\n')}

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –º–∞—Å—Å–∏–≤ —Å scores: [85, 23, 67, ...]
`

  const response = await callOpenRouter(MODEL_FILTER, prompt, 200)
  const scores = JSON.parse(response)

  return posts.filter((_, idx) => scores[idx] >= 50)
}
```

#### Stage 2: Deep Analysis (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø—Ä–æ—à–µ–¥—à–∏—Ö —Ñ–∏–ª—å—Ç—Ä)
```typescript
// –ò—Å–ø–æ–ª—å–∑—É–µ–º Claude Opus –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
const MODEL_ANALYSIS = 'anthropic/claude-opus-4-5'

async function extractPainPoints(posts: SocialPost[]) {
  const prompt = `
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ—Å—Ç—ã –∏ –∏–∑–≤–ª–µ–∫–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –±–æ–ª–∏.

–î–ª—è –ö–ê–ñ–î–û–ô –±–æ–ª–∏ –≤–µ—Ä–Ω–∏:
{
  "painText": "–ß–µ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –±–æ–ª–∏",
  "category": "TIME_MANAGEMENT|COST|TECHNICAL|...",
  "severity": "LOW|MEDIUM|HIGH|CRITICAL",
  "sentiment": -1.0 –¥–æ 1.0,
  "confidence": 0.0 –¥–æ 1.0,
  "keywords": ["–∫–ª—é—á–µ–≤—ã–µ", "—Å–ª–æ–≤–∞"],
  "context": "–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–æ—Å—Ç–∞",
  "evidence": "–ü—Ä—è–º–∞—è —Ü–∏—Ç–∞—Ç–∞ –∏–∑ –ø–æ—Å—Ç–∞"
}

–ü–æ—Å—Ç—ã:
${posts.map(p => `–ü–æ—Å—Ç –æ—Ç ${p.author}:\n${p.content}`).join('\n\n---\n\n')}

–í–µ—Ä–Ω–∏ JSON: { "pains": [...] }
`

  const response = await callOpenRouter(MODEL_ANALYSIS, prompt, 2000)
  return JSON.parse(response).pains
}
```

**–≠–∫–æ–Ω–æ–º–∏—è:**
- Stage 1 (Haiku): $0.25/1M —Ç–æ–∫–µ–Ω–æ–≤
- Stage 2 (Opus): —Ç–æ–ª—å–∫–æ –¥–ª—è ~30% –ø–æ—Å—Ç–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞
- –ò—Ç–æ–≥–æ–≤–∞—è —ç–∫–æ–Ω–æ–º–∏—è: ~60-70% vs –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –ø–æ—Å—Ç–æ–≤ Opus

---

## üìê –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è Database Schema

–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –∏ —É–ª—É—á—à–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É:

```prisma
enum SocialPlatform {
  REDDIT
  HACKERNEWS  // üÜï –î–æ–±–∞–≤–∏—Ç—å
  TWITTER
  THREADS
  INDIEHACKERS  // üÜï –ù–∞ –±—É–¥—É—â–µ–µ
}

model SocialPost {
  // ... existing fields

  // üÜï –î–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
  filterScore    Int?      // Score –∏–∑ Stage 1 filtering
  filteredAt     DateTime? // –ö–æ–≥–¥–∞ –±—ã–ª –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω

  // –£–ª—É—á—à–∏—Ç—å –∏–Ω–¥–µ–∫—Å—ã
  @@index([platform, publishedAt(sort: Desc)])
  @@index([platform, engagement(sort: Desc)])
  @@index([filterScore(sort: Desc)])
}

model ExtractedPain {
  // ... existing fields

  // üÜï –î–æ–±–∞–≤–∏—Ç—å evidence –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
  evidence       String?   @db.Text  // –ü—Ä—è–º–∞—è —Ü–∏—Ç–∞—Ç–∞
  sourceUrl      String?   // –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ—Å—Ç

  // –£–ª—É—á—à–∏—Ç—å –¥–ª—è semantic search
  @@index([workspaceId, frequency(sort: Desc)])
  @@index([workspaceId, severity, createdAt(sort: Desc)])
}
```

---

## üöÄ –ü–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –Ω–æ–≤—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤

### –®–∞–≥ 1: –î–æ–±–∞–≤–∏—Ç—å Hacker News support (3-4 –¥–Ω—è)

**1.1 Backend API** (1.5 –¥–Ω—è)
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è - –ø—Ä—è–º—ã–µ HTTP –∑–∞–ø—Ä–æ—Å—ã
```

- [ ] –°–æ–∑–¥–∞—Ç—å `lib/social/hackernews.ts` —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏:
  - `searchHackerNews(keyword, limit)`
  - `getHNItem(id)` –¥–ª—è –¥–µ—Ç–∞–ª–µ–π –ø–æ—Å—Ç–∞
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `app/api/pain-radar/scan/route.ts`:
  - –î–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É platform: 'HACKERNEWS'
  - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å HN API –≤–º–µ—Å—Ç–æ Reddit
- [ ] –î–æ–±–∞–≤–∏—Ç—å `HACKERNEWS` –≤ enum SocialPlatform

**1.2 UI Updates** (1 –¥–µ–Ω—å)
- [ ] –í KeywordManager –¥–æ–±–∞–≤–∏—Ç—å Platform selector (Reddit/HN)
- [ ] –í PostSelector –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å platform badge
- [ ] –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–æ—á–∫–∏ –ø–æ—Å—Ç–æ–≤ –ø–æ–¥ HN —Ñ–æ—Ä–º–∞—Ç

**1.3 Testing** (0.5 –¥–Ω—è)
- [ ] –¢–µ—Å—Ç —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è HN –ø–æ keyword
- [ ] –¢–µ—Å—Ç deduplication
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å AI –∞–Ω–∞–ª–∏–∑ HN –ø–æ—Å—Ç–æ–≤

**1.4 Migration** (1 –¥–µ–Ω—å)
- [ ] Prisma migration –¥–ª—è HACKERNEWS enum
- [ ] Deploy –∏ —Ç–µ—Å—Ç –Ω–∞ production

---

### –®–∞–≥ 2: –î–≤—É—Ö—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–π AI –∞–Ω–∞–ª–∏–∑ (2 –¥–Ω—è)

**2.1 Filtering Stage** (1 –¥–µ–Ω—å)
- [ ] –°–æ–∑–¥–∞—Ç—å `lib/ai/filter-posts.ts`:
  - –§—É–Ω–∫—Ü–∏—è `filterRelevantPosts()` —Å Haiku
  - Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ (50 –ø–æ—Å—Ç–æ–≤ –∑–∞ —Ä–∞–∑)
  - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ filterScore –≤ –ë–î
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `app/api/pain-radar/analyze/route.ts`:
  - –°–Ω–∞—á–∞–ª–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –ø–æ—Å—Ç–æ–≤
  - –ó–∞—Ç–µ–º –∞–Ω–∞–ª–∏–∑ —Ç–æ–ª—å–∫–æ —Å score >= 50

**2.2 Deep Analysis** (1 –¥–µ–Ω—å)
- [ ] –£–ª—É—á—à–∏—Ç—å –ø—Ä–æ–º–ø—Ç –≤ `lib/ai.ts:extractPainsFromPosts()`:
  - –î–æ–±–∞–≤–∏—Ç—å extraction evidence (—Ü–∏—Ç–∞—Ç)
  - –£–ª—É—á—à–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É JSON
  - –£–≤–µ–ª–∏—á–∏—Ç—å context –¥–æ 4000 —Ç–æ–∫–µ–Ω–æ–≤
- [ ] –î–æ–±–∞–≤–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ evidence –≤ –ë–î

---

### –®–∞–≥ 3: IndieHackers Integration (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, 3-4 –¥–Ω—è)

**–ü–æ–¥—Ö–æ–¥:** Web scraping (—Ç.–∫. –Ω–µ—Ç –ø—É–±–ª–∏—á–Ω–æ–≥–æ API)

```typescript
// lib/social/indiehackers.ts
import * as cheerio from 'cheerio'

export async function scrapeIndieHackers(keyword: string) {
  const url = `https://www.indiehackers.com/search?q=${encodeURIComponent(keyword)}`
  const response = await fetch(url)
  const html = await response.text()
  const $ = cheerio.load(html)

  const posts = []
  $('.feed-item').each((i, el) => {
    posts.push({
      id: $(el).attr('data-id'),
      author: $(el).find('.author').text(),
      title: $(el).find('.feed-item__title').text(),
      content: $(el).find('.feed-item__content').text(),
      url: 'https://www.indiehackers.com' + $(el).find('a').attr('href'),
      likes: parseInt($(el).find('.upvote-count').text()),
      comments: parseInt($(el).find('.comment-count').text()),
    })
  })

  return posts
}
```

‚ö†Ô∏è **–†–∏—Å–∫–∏:**
- –ú–æ–∂–µ—Ç –Ω–∞—Ä—É—à–∞—Ç—å ToS IndieHackers
- –•—Ä—É–ø–∫–∏–π –∫–æ–¥ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç HTML —Å—Ç—Ä—É–∫—Ç—É—Ä—ã)
- –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–ª—è—Ç—å delays –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞:** –†—É—á–Ω–æ–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ IH + —Ä—É—á–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Å—Ç–æ–≤

---

## üí° Best Practices –∏–∑ —É—Å–ø–µ—à–Ω—ã—Ö –∫–µ–π—Å–æ–≤

### 1. –û—Ç PainOnSocial

**–ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
- ‚úÖ –ö—É—Ä–∞—Ç–æ—Ä—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥: 30+ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö —Å–∞–±—Ä–µ–¥–¥–∏—Ç–æ–≤
- ‚úÖ AI scoring –ø–æ frequency + intensity + engagement
- ‚úÖ Evidence-based: —Ü–∏—Ç–∞—Ç—ã + permalink + upvotes
- ‚úÖ Timeframe filtering: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7/30/90 –¥–Ω–µ–π

**–ü—Ä–∏–º–µ–Ω—è–µ–º:**
```typescript
// –ü—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏
const targetSubreddits = [
  'startups',
  'entrepreneur',
  'smallbusiness',
  // ... –∫—É—Ä–∞—Ç–æ—Ä—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
]

// –ü—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ
const painScore = calculatePainScore({
  frequency: mentionCount,
  intensity: sentimentScore * -1,  // –ù–µ–≥–∞—Ç–∏–≤ = –±–æ–ª—å
  engagement: upvotes + comments * 2
})
```

---

### 2. –û—Ç Reddit_Scrapper (GitHub)

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:**
- ‚úÖ Batch API –¥–ª—è GPT (—ç–∫–æ–Ω–æ–º–∏—è 50%)
- ‚úÖ SQLite –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞
- ‚úÖ Age filtering: 5-90 –¥–Ω–µ–π
- ‚úÖ Monthly budget caps
- ‚úÖ Primary/exploratory subreddit rotation

**–ü—Ä–∏–º–µ–Ω—è–µ–º:**
```typescript
// Rate limiting config
const LIMITS = {
  REDDIT_RPM: 60,
  AI_BATCH_SIZE: 10,
  MONTHLY_BUDGET_USD: 50,
  POST_AGE_MIN_DAYS: 5,
  POST_AGE_MAX_DAYS: 90,
}

// Cost tracking
async function trackAICost(tokensUsed: number, model: string) {
  const costs = {
    'claude-3-haiku': 0.25 / 1_000_000,
    'claude-opus-4-5': 15 / 1_000_000,  // Input
  }

  const cost = tokensUsed * costs[model]
  await db.aiUsage.create({ /* ... */ })

  const monthTotal = await db.aiUsage.aggregate({ /* current month */ })
  if (monthTotal > LIMITS.MONTHLY_BUDGET_USD) {
    throw new Error('Monthly AI budget exceeded')
  }
}
```

---

### 3. –û—Ç Algolia HN API integration

**–õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –ø–æ–∏—Å–∫–∞:**
```typescript
// –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –±–æ–ª–µ–π
const searchQueries = [
  'struggling with',
  'pain point',
  'frustrated by',
  'wish there was',
  'looking for solution',
  'does anyone know',
  'help with',
]

// –î–ª—è –∫–∞–∂–¥–æ–≥–æ keyword
for (const query of searchQueries) {
  const results = await searchHackerNews(
    `${keyword} ${query}`,
    { tags: 'ask_hn', numericFilters: 'points>20' }
  )
}
```

---

## üìä –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ AI –∞–Ω–∞–ª–∏–∑–∞

### –¢–µ–∫—É—â–∏–π –ø–æ–¥—Ö–æ–¥ (–≤—Å–µ –ø–æ—Å—Ç—ã —á–µ—Ä–µ–∑ Opus)
```
100 –ø–æ—Å—Ç–æ–≤ √ó 1000 —Ç–æ–∫–µ–Ω–æ–≤ = 100k —Ç–æ–∫–µ–Ω–æ–≤
100k √ó $15/1M = $1.50 –∑–∞ 100 –ø–æ—Å—Ç–æ–≤
```

### –î–≤—É—Ö—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–π –ø–æ–¥—Ö–æ–¥
```
Stage 1 (Haiku):
100 –ø–æ—Å—Ç–æ–≤ √ó 500 —Ç–æ–∫–µ–Ω–æ–≤ = 50k —Ç–æ–∫–µ–Ω–æ–≤
50k √ó $0.25/1M = $0.0125

Stage 2 (Opus) - —Ç–æ–ª—å–∫–æ 30% –ø—Ä–æ—à–ª–∏ —Ñ–∏–ª—å—Ç—Ä:
30 –ø–æ—Å—Ç–æ–≤ √ó 1500 —Ç–æ–∫–µ–Ω–æ–≤ = 45k —Ç–æ–∫–µ–Ω–æ–≤
45k √ó $15/1M = $0.675

–ò–¢–û–ì–û: $0.0125 + $0.675 = $0.69 –∑–∞ 100 –ø–æ—Å—Ç–æ–≤
–≠–∫–æ–Ω–æ–º–∏—è: 54%
```

---

## üéØ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1 (Must Have –¥–ª—è MVP)
1. ‚úÖ Reddit —á–µ—Ä–µ–∑ snoowrap (—É–∂–µ –≤ –ø–ª–∞–Ω–µ)
2. üÜï Hacker News —á–µ—Ä–µ–∑ Algolia API
3. üÜï –î–≤—É—Ö—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–π AI –∞–Ω–∞–ª–∏–∑ (Haiku + Opus)
4. ‚úÖ Evidence extraction (—Ü–∏—Ç–∞—Ç—ã –∏–∑ –ø–æ—Å—Ç–æ–≤)

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2 (Nice to Have)
5. üîú IndieHackers scraping –∏–ª–∏ —Ä—É—á–Ω–æ–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
6. üîú ProductHunt API integration
7. üîú Automated subreddit/source discovery

### –ù–ï —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è MVP
- ‚ùå Twitter/X API (—Å–ª–∏—à–∫–æ–º –¥–æ—Ä–æ–≥–æ)
- ‚ùå Threads (—Ç—Ä–µ–±—É–µ—Ç Business account)
- ‚ùå Instagram (–Ω–µ—Ç API)

---

## üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏

### –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ API –∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º:
- [Top Social Listening APIs in 2026](https://data365.co/blog/top-social-listening-api)
- [Best Reddit Monitoring Tool](https://painonsocial.com/blog/best-reddit-monitoring-tool-2)
- [Threads API Documentation](https://www.postman.com/meta/threads/documentation/dht3nzz/threads-api)
- [Reddit API Alternative Options](https://painonsocial.com/blog/reddit-api-alternative)
- [Best Twitter API Alternatives 2026](https://www.xpoz.ai/blog/comparisons/best-twitter-api-alternatives-2026/)

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:
- [GitHub: Reddit_Scrapper with GPT](https://github.com/Mohamedsaleh14/Reddit_Scrapper)
- [GitHub: reddit-painpointer](https://github.com/the-wc/reddit-painpointer)
- [GitHub: reddit-pain-point-analyzer](https://github.com/vriznet/reddit-pain-point-analyzer)
- [Algolia HN Search API](https://hn.algolia.com/api)
- [Unlocking Hacker News with Algolia API](https://deepeshsoni.com/archives/70)

### Best Practices –∏ –∫–µ–π—Å—ã:
- [PainOnSocial: Pain Point Analysis Guide](https://painonsocial.com/blog/pain-point-analysis-guide-2)
- [How to Find Customer Pain Points on Reddit](https://painonsocial.com/blog/find-customer-pain-points-reddit)
- [35 Indie Hackers Lucrative Niches](https://www.chaodit.com/how-35-indie-hackers-unearthed-lucrative-niches-a-field-guide-to-turning-real-world-pain-points-into-profitable-products)
- [IndieHackers: How to Find Pain Points](https://www.indiehackers.com/forum/how-did-you-find-the-pain-points-2ae1bf64cc)

---

## ‚úÖ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. **–û–±—Å—É–¥–∏—Ç—å —Å –∫–æ–º–∞–Ω–¥–æ–π:**
   - –°–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã (HN vs IH vs –¥–≤—É—Ö—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–π AI)
   - –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –±—é–¥–∂–µ—Ç –Ω–∞ AI –∞–Ω–∞–ª–∏–∑
   - –í—ã–±—Ä–∞—Ç—å —Ü–µ–ª–µ–≤—ã–µ subreddits –∏ HN tags

2. **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞:**
   - –ü–æ–ª—É—á–∏—Ç—å Reddit API credentials (—É–∂–µ –≤ –ø–ª–∞–Ω–µ)
   - –ù–∞—Å—Ç—Ä–æ–∏—Ç—å rate limiting
   - –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏–∏ –ë–î

3. **–ù–∞—á–∞—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É:**
   - –°–ª–µ–¥–æ–≤–∞—Ç—å –ø–ª–∞–Ω—É –∏–∑ –®–∞–≥–∞ 1-3 –≤—ã—à–µ
   - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –º–∞–ª—ã—Ö –æ–±—ä–µ–º–∞—Ö –¥–∞–Ω–Ω—ã—Ö
   - –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å AI costs

---

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 2026-01-21
**–ê–≤—Ç–æ—Ä:** Claude Sonnet 4.5
**–°—Ç–∞—Ç—É—Å:** Ready for implementation
