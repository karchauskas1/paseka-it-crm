import { BaseScraper } from './base-scraper'
import { ParsedProfile, ParsedPost, ParseResult, ParserConfig } from './types'

/**
 * –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω Scraper
 * –ë–æ–ª—å—à–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è, –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–Ω—Ç, –∏—Å—Ç–æ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞/–Ω–µ—É–¥–∞—á
 */
export class ZenScraper extends BaseScraper {
  private baseUrl = 'https://dzen.ru'

  constructor(config?: ParserConfig) {
    super({
      ...config,
      delay: 2000, // –î–∑–µ–Ω –º–µ–¥–ª–µ–Ω–Ω—ã–π
    })
  }

  async scrapePopular(): Promise<ParseResult> {
    const startTime = Date.now()
    const posts: ParsedPost[] = []
    const errors: string[] = []

    try {
      await this.init()
      if (!this.page) throw new Error('Page not initialized')

      // –ì–ª–∞–≤–Ω–∞—è –ª–µ–Ω—Ç–∞ –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è
      await this.page.goto(this.baseUrl, { waitUntil: 'domcontentloaded' })
      await this.delay(3000)
      await this.scrollToBottom(this.config.maxPages)

      const articlesData = await this.page.evaluate(() => {
        const items: any[] = []
        const processedUrls = new Set<string>()

        // –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å–∏
        document.querySelectorAll('a[href*="/a/"]').forEach((link) => {
          const url = (link as HTMLAnchorElement).href
          if (!url || !url.includes('/a/') || processedUrls.has(url)) return

          // –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å—Å—ã–ª–∫–∏ –∏ –æ—á–∏—â–∞–µ–º –æ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
          let fullText = link.textContent?.trim() || ''
          if (!fullText) return

          // –£–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (—á–∏—Ç–∞–ª–∏, –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤, –¥–∞—Ç—ã)
          // –ü—Ä–∏–º–µ—Ä: "Motor.ru7180 —á–∏—Ç–∞–ª–∏ ¬∑ 1 –¥–µ–Ω—å –Ω–∞–∑–∞–¥ –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏ —Ç—É—Ç"
          // –ù—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å "–ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏ —Ç—É—Ç"

          // –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
          let title = fullText
            .replace(/^\s*[\w\s\.\-]+\d+[\d,\s]*\s*(—Ç—ã—Å|—á–∏—Ç–∞–ª–∏|–ø—Ä–æ—Å–º–æ—Ç—Ä|–ø–æ–¥–ø–∏—Å—á–∏–∫)[^\n]*/gi, '') // –ê–≤—Ç–æ—Ä + —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            .replace(/\d+\s*(—á–∏—Ç–∞–ª–∏|–ø—Ä–æ—Å–º–æ—Ç—Ä|–¥–µ–Ω—å|—á–∞—Å|–º–∏–Ω—É—Ç)[^\n]*/gi, '') // –û—Å—Ç–∞–≤—à–∞—è—Å—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            .replace(/–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è/gi, '')
            .replace(/¬∑/g, '')
            .trim()

          // –ï—Å–ª–∏ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å, –±–µ—Ä—ë–º –∫–∞–∫ –µ—Å—Ç—å –Ω–æ –∫–æ—Ä–æ—á–µ
          if (title.length < 15) {
            // –ë–µ—Ä—ë–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ –ø–æ—Å–ª–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            const parts = fullText.split(/\n/)
            if (parts.length > 1) {
              title = parts.find(p => p.trim().length > 20) || parts[parts.length - 1]
            } else {
              title = fullText.slice(0, 200)
            }
          }

          title = title.trim()
          if (!title || title.length < 15 || title.length > 300) return

          processedUrls.add(url)

          // –ê–≤—Ç–æ—Ä - –ø–µ—Ä–≤–∞—è —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ –¥–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
          let author = ''
          const authorMatch = fullText.match(/^([–ê-–Ø–∞-—èA-Za-z\s\.\-]+?)(?:\d|—Ç—ã—Å|—á–∏—Ç–∞–ª–∏)/i)
          if (authorMatch) {
            author = authorMatch[1].trim()
          }

          // –ü—Ä–æ—Å–º–æ—Ç—Ä—ã –∏ –ª–∞–π–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞
          const viewsMatch = fullText.match(/([\d,.\s]+[–ö–∫Kk–ú–º]?)\s*–ø—Ä–æ—Å–º–æ—Ç—Ä/i)
          let views = 0
          if (viewsMatch) {
            const num = viewsMatch[1].replace(/[\s,]/g, '').toLowerCase()
            if (num.includes('–∫') || num.includes('k')) views = parseFloat(num) * 1000
            else if (num.includes('–º') || num.includes('m')) views = parseFloat(num) * 1000000
            else views = parseFloat(num)
          }

          const likesMatch = fullText.match(/([\d,]+)\s*–ª–∞–π–∫/i) || fullText.match(/üëç\s*([\d,]+)/i)
          const likes = likesMatch ? parseInt(likesMatch[1].replace(/\D/g, '')) : 0

          items.push({
            title,
            url,
            author,
            views: Math.round(views),
            likes,
          })
        })

        return items
      })

      console.log(`–ù–∞–π–¥–µ–Ω–æ ${articlesData.length} —Å—Ç–∞—Ç–µ–π –Ω–∞ –î–∑–µ–Ω–µ`)

      for (const data of articlesData.slice(0, this.config.maxPosts)) {
        const postIdMatch = data.url.match(/\/a\/([^/?]+)/)
        posts.push({
          platform: 'zen',
          postId: postIdMatch ? postIdMatch[1] : data.url,
          title: data.title,
          content: data.title,
          authorUsername: data.author || 'unknown',
          authorDisplayName: data.author,
          url: data.url,
          likes: data.likes || undefined,
          views: data.views || undefined,
          parsedAt: new Date(),
        })
      }
    } catch (err) {
      errors.push(`–û—à–∏–±–∫–∞ –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω: ${err}`)
    } finally {
      await this.close()
    }

    return {
      success: posts.length > 0,
      platform: 'zen',
      profiles: [],
      posts,
      errors,
      stats: {
        profilesFound: 0,
        postsFound: posts.length,
        duration: Date.now() - startTime,
      },
    }
  }

  async scrapeSearch(query: string): Promise<ParseResult> {
    const startTime = Date.now()
    const posts: ParsedPost[] = []
    const errors: string[] = []

    try {
      await this.init()
      if (!this.page) throw new Error('Page not initialized')

      // –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –Ø–Ω–¥–µ–∫—Å —Å —Ñ–∏–ª—å—Ç—Ä–æ–º site:dzen.ru
      const searchUrl = `https://yandex.ru/search/?text=${encodeURIComponent(query + ' site:dzen.ru')}`
      console.log(`–ü–æ–∏—Å–∫ –î–∑–µ–Ω —á–µ—Ä–µ–∑ –Ø–Ω–¥–µ–∫—Å: ${searchUrl}`)
      await this.page.goto(searchUrl, { waitUntil: 'domcontentloaded' })
      await this.delay(3000)
      await this.scrollToBottom(Math.min(this.config.maxPages || 3, 2))

      const articlesData = await this.page.evaluate(() => {
        const items: any[] = []
        const processedUrls = new Set<string>()

        // –ò—â–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –Ø–Ω–¥–µ–∫—Å–∞
        document.querySelectorAll('a[href*="dzen.ru/a/"], a[href*="zen.yandex.ru/media/"]').forEach((link) => {
          const url = (link as HTMLAnchorElement).href
          if (!url || processedUrls.has(url)) return

          // –û—á–∏—â–∞–µ–º URL –æ—Ç —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤ –Ø–Ω–¥–µ–∫—Å–∞
          let cleanUrl = url
          if (url.includes('yandex.ru/clck')) {
            const match = url.match(/url=([^&]+)/)
            if (match) cleanUrl = decodeURIComponent(match[1])
          }

          const baseUrl = cleanUrl.split('?')[0]
          if (processedUrls.has(baseUrl)) return
          processedUrls.add(baseUrl)

          // –ó–∞–≥–æ–ª–æ–≤–æ–∫ - —Ç–µ–∫—Å—Ç —Å—Å—ã–ª–∫–∏ –∏–ª–∏ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
          let title = link.textContent?.trim() || ''

          // –ï—Å–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π, –∏—â–µ–º –≤ —Ä–æ–¥–∏—Ç–µ–ª–µ
          if (title.length < 20) {
            const parent = link.closest('[class*="organic"]') || link.parentElement?.parentElement
            const heading = parent?.querySelector('h2, h3, [class*="title"]')
            if (heading) title = heading.textContent?.trim() || title
          }

          if (!title || title.length < 15 || title.length > 300) return

          items.push({
            title,
            url: baseUrl,
          })
        })

        return items
      })

      console.log(`–ù–∞–π–¥–µ–Ω–æ ${articlesData.length} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –î–∑–µ–Ω–µ –¥–ª—è "${query}"`)

      for (const data of articlesData.slice(0, this.config.maxPosts)) {
        const postIdMatch = data.url.match(/\/a\/([^/?]+)/)
        posts.push({
          platform: 'zen',
          postId: postIdMatch ? postIdMatch[1] : data.url,
          title: data.title,
          content: data.title,
          authorUsername: data.author || 'unknown',
          url: data.url,
          parsedAt: new Date(),
        })
      }
    } catch (err) {
      errors.push(`–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –î–∑–µ–Ω: ${err}`)
    } finally {
      await this.close()
    }

    return {
      success: posts.length > 0,
      platform: 'zen',
      profiles: [],
      posts,
      errors,
      stats: {
        profilesFound: 0,
        postsFound: posts.length,
        duration: Date.now() - startTime,
      },
    }
  }

  async scrapeProfile(channelId: string): Promise<ParsedProfile | null> {
    try {
      await this.init()
      if (!this.page) throw new Error('Page not initialized')

      // –ö–∞–Ω–∞–ª –Ω–∞ –î–∑–µ–Ω–µ
      await this.page.goto(`${this.baseUrl}/${channelId}`, {
        waitUntil: 'domcontentloaded'
      })
      await this.delay(3000)

      const profileData = await this.page.evaluate(() => {
        const displayName = document.querySelector('h1, [class*="channel-name"], [class*="title"]')?.textContent?.trim()
        const bio = document.querySelector('[class*="description"], [class*="about"]')?.textContent?.trim()
        const avatarUrl = (document.querySelector('[class*="avatar"] img, [class*="channel-logo"] img') as HTMLImageElement)?.src

        const text = document.body.textContent || ''
        const subscribersMatch = text.match(/([\d,.\s]+[–ö–∫–ú–º]?)\s*–ø–æ–¥–ø–∏—Å—á–∏–∫/i)
        let subscribers = undefined
        if (subscribersMatch) {
          const num = subscribersMatch[1].replace(/[\s,]/g, '').toLowerCase()
          if (num.includes('–∫') || num.includes('k')) subscribers = parseFloat(num) * 1000
          else if (num.includes('–º') || num.includes('m')) subscribers = parseFloat(num) * 1000000
          else subscribers = parseFloat(num)
        }

        return { displayName, bio, avatarUrl, subscribers: subscribers ? Math.round(subscribers) : undefined }
      })

      return {
        platform: 'zen',
        username: channelId,
        displayName: profileData.displayName || channelId,
        bio: profileData.bio,
        followers: profileData.subscribers,
        profileUrl: `${this.baseUrl}/${channelId}`,
        avatarUrl: profileData.avatarUrl,
        parsedAt: new Date(),
      }
    } catch (err) {
      console.error(`–û—à–∏–±–∫–∞ –ø—Ä–æ—Ñ–∏–ª—è –î–∑–µ–Ω ${channelId}:`, err)
      return null
    } finally {
      await this.close()
    }
  }

  // –ü–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
  async scrapeCategory(category: string): Promise<ParseResult> {
    const startTime = Date.now()
    const posts: ParsedPost[] = []
    const errors: string[] = []

    try {
      await this.init()
      if (!this.page) throw new Error('Page not initialized')

      // –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: business, technology, marketing, etc.
      await this.page.goto(`${this.baseUrl}/category/${category}`, {
        waitUntil: 'domcontentloaded'
      })
      await this.delay(3000)
      await this.scrollToBottom(this.config.maxPages)

      const articlesData = await this.page.evaluate((cat) => {
        const items: any[] = []
        const processedUrls = new Set<string>()

        document.querySelectorAll('a[href*="/a/"]').forEach((link) => {
          const url = (link as HTMLAnchorElement).href
          if (!url || processedUrls.has(url)) return
          processedUrls.add(url)

          const title = link.textContent?.trim()
          if (!title || title.length < 15 || title.length > 300) return

          items.push({
            title,
            url,
            category: cat,
          })
        })

        return items
      }, category)

      for (const data of articlesData.slice(0, this.config.maxPosts)) {
        const postIdMatch = data.url.match(/\/a\/([^/?]+)/)
        posts.push({
          platform: 'zen',
          postId: postIdMatch ? postIdMatch[1] : data.url,
          title: data.title,
          content: data.title,
          authorUsername: 'unknown',
          url: data.url,
          category: data.category,
          parsedAt: new Date(),
        })
      }
    } catch (err) {
      errors.push(`–û—à–∏–±–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –î–∑–µ–Ω ${category}: ${err}`)
    } finally {
      await this.close()
    }

    return {
      success: posts.length > 0,
      platform: 'zen',
      profiles: [],
      posts,
      errors,
      stats: {
        profilesFound: 0,
        postsFound: posts.length,
        duration: Date.now() - startTime,
      },
    }
  }
}
